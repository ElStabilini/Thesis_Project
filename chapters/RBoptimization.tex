\chapter{RB fidelity optimization}
The calibration procedure described in Section \ref{sec:calibration} is typically time-consuming and demands significant experimental expertise, particularly when aiming for state-of-the-art performance. 
In the work I presented in the previous chapter, the calibration process began from a pre-existing, even if suboptimal, configuration. 
The goal was to enhance the quality of single-qubit gates by using the available \Qibocal protocols.

Even under these ovverall favorable initial conditions, the effort required to refine gate performance showed the limitations of manual calibration approaches. 
As quantum processors scale in both qubit count and architectural complexity, manual calibration becomes increasingly complex. 
Frequent recalibrations are necessary to mitigate the effects of parameter drift and environmental fluctuations, especially in superconducting qubit platforms \cite{krantz_quantum_2019}.

Furthermore, as gate fidelities approach the fault-tolerance threshold, enabling practical quantum computation across a variety of applications, accurate control of single-qubit gates becomes essential. 
The fidelity of an individual gate quantifies its average operational performance, directly impacting circuit-level error rates and representing a critical figure of merit for quantum processors. 
However, improving gate fidelity remains challenging because of the nontrivial mapping between gate parameters and the underlying process matrix, and errors from state preparation and measurement (SPAM) can make it difficult to distinguish between different sources of error.

In this chapter, i present an initial attempt to address the dual challenges of calibration complexity and residual gate errors. 
The goal is to find calibration procedures that are not only effective but also repeatable and accessible to non-expert users, lowering the entry barrier for experimental optimization of superconducting qubits. 
Building on the approach proposed in \cite{kelly_optimal_2014}, which demonstrated that optimizing the sequence fidelity at a fixed length of randomized benchmarking (RB) can improve gate performance, we explored an automatic recalibration procedure based on randomized benchmarking fidelity as an optimization target.

The focus of this first study is the optimization of single-qubit gate fidelity, that was chosen both for its foundational importance and its relative accessibility compared to more complex operations.
Starting from single-qubit gates thus provides a practical and effective testbed for validating optimization algorithms before extending them to more complex multi-qubit operations.
The results presented in this chapter shows how different optimization strategies perform when applied to improving gate fidelity in realistic experimental settings.

\section{Randomized Benchmarking}\label{sec:RBsection}
A strong limitation to the realization of quantum computing technologies is the loss of coherence that happens as a consequence of the application of many sequential quantum gates to to the quibts.
A possible approach to characterize gate error is the quantum process tomography which allows the experimenter to establish the behaviour of a quantum gates. 
The main drawback of this approach is that process tomography can be very time consumig since its time complexity scales exponentially with the number of qubits involved \cite{QPTomography} and the result is affected by state preparation and measurements (SPAM) errors.

To overcome these limitations, randomized benchmarking (RB) was introduced and is currently widely used to quantify the avarage error rate for a set of quantum gates.

The main idea is that the error resulting from the combined action of random unitary gates, which are drawn from a uniform distribution according to the Haar measure \cite{Mele_2024} and applied sequentially to the qubit, averages out to effectively behave like a depolarizing channel \cite{Emerson_2005_RB}.
This last consideration simplifies the characterization of noise because it removes dependence on specific error structures and allows fidelity to be extracted through a simple exponential decay.

It was later shown that it is possible to simplify this procedure even more, by restricting the unitaries to gates in the Clifford group \footnote{unitary rotations mapping the group of Puali operators in itself} and by not requiring that the sequence is strictly self-inverting \cite{knill_randomized_2008}.
The fundamental principle of RB is the application of sequences of randomly selected quantum gates from the Clifford group $\mathcal{C}$ followed by an inversion gate which, in absence of noise, return the system to its initial state. 
For real systems, where noise is present, the observed survival probability provides an estimate of the avarage gate fidelity.

The standard RB protocols consist of the following steps:\begin{enumerate}\label{routine:RB}
    \item Initialize the system in ground state $\ket{0}$
    \item For each sequence-length $m$ build a sequence of $m$ randomly drawn Clifford gates $C_1, C_2, ..., C_m$
    \item Determine the inverse gate $C_{m+1}=(C_m\circ...\circ C_1)^{-1}$
    \item Measure $C_{m+1}\circ C_m \circ ...\circ C_1 \ket{0}$
\end{enumerate}
The process must be repeated for multiple sequence of the same length and with varying length.

In an ideal systems, without noise, we should have 
\begin{equation}\label{eq:CliffordIdeal}
    C_{m+1}\circ C_m \circ ...\circ C_1 \ket{0} = (C_m\circ...\circ C_1)^{-1}\circ(C_m\circ...\circ C_1)\ket{0} = \ket{0}.
\end{equation}
However in real systems Equation \ref{eq:CliffordIdeal} does not hold; instead randomization with Clifford gates behave as a depolarizing channel \ref{eq:depolarizing_channel} with depolarization probability $d$.\\
The survival probability of the initial state $\ket{0}$ for different sequence lengths $m$ follows the exponential decay model \begin{equation}\label{eq:RB_decay}
    F(m) = Ap^m +B,
\end{equation}
where $1-p$ is the rate of depolarization and $A$ and $B$ capture the state preparation and measurement errors.\\
The parameter $p$ is directly related to the depolarization probability $d$ through the avarage gate fidelity $F$ which, for a depolarizing channel, is given by \begin{equation}
    F = 1 - \frac{d}{2^n - 1}\label{eq:avarage_gate_fidelity},
\end{equation}
where $n$ is the nuber of qubits.
%For the details of the calculations to obtain eq. \ref{eq:avarage_gate_fidelity} see \hyperref[app:AppendixC]{Appendix C}.
The avarage error per Clifford gate $\varepsilon_{Clifford}$ can be computed as \begin{equation}
    \varepsilon_{Clifford} = 1 - F \label{eq:avg_error_Clifford_gate},
\end{equation}
where $F$ is the avarage gate fidelity. 
Sobstituting in \ref{eq:avg_error_Clifford_gate} the formula for the avarage gate fidelity \ref{eq:avarage_gate_fidelity} we obtain \begin{equation}
    \varepsilon_{Clifford} = \frac{d}{2^n -1} = \frac{1-p}{1-2^{-n}},
\end{equation}
which shows how the avarage error per Clifford gate is directly connected to the exponential decay rate.

\section{RB evaluation and optimization}
%TODO: inserire una introduzione per questa sezione

\subsection{\Qibolab native gates}
As discussed at the beginning of the chapter, the primary goal of this work is to explore an automated calibration approach aimed at optimizing the single-gate fidelity of logical gates. 
In particular, we focused on the calibration of the $R_X$ gate, which corresponds to a microwave pulse with a specific frequency, amplitude, and duration that induces a rotation of the qubit state by an angle of $\pi$ around the $x$-axis of the Bloch sphere.

The choice to optimize the $R_X$ gate dependes on its role as one of the native gates in the \texttt{Qibolab} control stack. 
Native gates are physical operations that are directly implementable by the hardware, in contrast to abstract logical gates, which must be compiled into sequences of these hardware-supported primitives. 
In the case of \texttt{Qibolab}\footnote{At least for version 0.1 of \Qibolab}, the native gate set consists of $R_X$ pulses combined with virtual-Z (VZ) gates. 
This native gate basis is both efficient to implement and expressive enough to support universal quantum computation.

Indeed, it can be shown that any arbitrary single-qubit unitary operation $ U(\gamma, \theta, \phi) \in SU(2) $ can be expressed, up to a global phase, as a sequence of rotations around the $z$ and $x$ axes of the Bloch sphere:
\begin{equation}
U(\gamma, \theta, \phi) = R_Z(\gamma) R_X(\theta) R_Z(\phi).
\end{equation}
This decomposition ensures that all single-qubit operations can be realized using a combination of $ R_X $ and $ R_Z $ rotations. 

When a qubit is driven by a resonant microwave pulse (with detuning $ \delta = 0 $), the resulting evolution is a rotation around an axis $\hat{n} = (\cos\phi, -\sin\phi, 0)$ lying in the equatorial plane of the Bloch sphere. 
The associated unitary can be written as:
\begin{equation}
R_{\hat{n}(\phi)}(\theta) = \exp\left( -i \frac{\theta}{2} \left[ \cos(\phi)\sigma_x - \sin(\phi)\sigma_y \right] \right).
\end{equation}

This operation can be equivalently expressed through conjugation of an $R_X$ rotation by two $R_Z$ rotations:
\begin{equation}
R_{\hat{n}(\phi)}(\theta) = R_Z(-\phi) R_X(\theta) R_Z(\phi) = U(-\phi, \theta, \phi).
\end{equation}
From this, it follows that any arbitrary unitary $ U(\gamma, \theta, \phi) $ can be implemented as:
\begin{equation}
U(\gamma, \theta, \phi) = R_Z(\gamma + \phi) \cdot R_Z(-\phi) R_X(\theta) R_Z(\phi) = R_Z(\gamma + \phi) \cdot U(-\phi, \theta, \phi).
\end{equation}

Note that, in practice, this final $R_Z$ rotation does not need to be realized as a physical pulse. 
Instead, it can be implemented virtually by adjusting the phase reference of subsequent pulses, a technique known as the virtual-Z gate\cite{McKay_2017}. \\
The ability to compose any single-qubit gate using only $R_X$ and virtual-Z operations \cite{boykin1999universalfaulttolerantquantumcomputing} confirms the sufficiency of this native gate set for universal single-qubit control. For instance, even a restricted $ R_X $ rotation such as $ R_X(\pi) $, when combined with arbitrary-angle $ R_Z $ gates, forms a universal set due to the non-commuting nature of these operations. By alternating $ R_X(\pi) $ pulses with phase-adjustable $ R_Z $ gates, one can synthesize any $ SU(2) $ unitary up to global phase.

Given these consideration, the optimization experiments described in the following sections focus on maximizing the $R_X$ gate fidelity using RB fidelity as a performance metric. 

\subsection{RB evaluation parameters}
In the results presented in the following, I employed the randomized benchmarking (RB) routine implemented in \Qibocal, an example of which is shown in Section \ref{sec:RB_calibration}. 
This routine was used consistently across all tests, with the following set of parameters: I used $1000$ unique random Clifford sequences (\texttt{num\_of\_sequences = 1000}), ensuring robust statistical reliability across different realizations of gate noise. 
Each sequence was evaluated at increasing circuit depths up to a maximum of $1000$ Clifford gates (\texttt{max\_circuit\_depth = 1000}), with the depths spaced by increments of $10$ (\texttt{delta\_clifford = 10}), resulting in benchmarking points at depths of $1, 10, 20, \ldots, 1000$. 
For each depth and random sequence, I generated only one instance (\texttt{n\_avg = 1}), meaning that each sequence was distinct and not repeated with the same gate pattern. 
Consequently, statistical averaging was achieved across the ensemble of random sequences at each depth rather than by repeating individual circuits. 
To ensure high confidence in the estimation of the survival probabilities, each circuit was executed with $2000$ measurement shots. %TODO: verify and check
\footnote{All experiments and results presented in this chapter were performed using version 0.1 of \Qibocal. This means that the parameters used to execute the \texttt{rb\_ondevice} routine, as described above, refer specifically to version 0.1. At the time of writing, version 0.2 of \Qibocal has been released and is actively maintained. As a result, the available parameters for running the RB routine may have changed and might no longer correspond exactly to those described in this text.}

\subsection{Parametri da ottimizzare}
%TODO: descrivere quali parametri sto cercando di ottimizzare, per quali gate, perchè quella gate (è la mia native gate) e come procedo (quindi prima cerco di fare un fine tuning)
%descrivere anche il fatto che in realtà questo procedimento di fine tuning non è così banale e che può decisamente influenzare i risultati (spiegare come sono inizializzati i parametri per l'ottimizzazione)
I parametri su cui è stata performata l'ottimizzazione sulla base della gate infidelity ottenuta dall'RB come cost function sono 3 (voglio ottimizare la porta logica $RX(\pi)$): frequenza, ampiezza e forma dell'impulso.
Per quanto rigaurda la forma dell'impulso in particolare il parametro da ottimizzare era il parametro $\beta$ dell'impulso di DRAG, vale a dire il parametro moltiplicativo sulla seconda quadratura.
Questo significa che la closed loop optimization che è stata realizzata è avvenuta secondo un procedimento simile a quello descritto nel paper ORBIT \cite{kelly_optimal_2014}
%TODO: spiegare un attimo meglio che cos'è ORBIT (Optimal Randomized Benchmarking)

%TODO: inserire code snippet dove mostro come inizializzo i parametri 


In un secondo momento invece è stata valuata anche l'evoluzione della gate fidelity ottenuta tramite RB ottimizzando solamente i parametri di ampiezza e frequenza dell'$RX(\pi)$ e tenendo un impulso Gaussiano.


%TODO: try to run at least once the NM from not-fine tuned

\section{Scipy optimization methods}\label{Sec:OptimizationMethods}

\subsection{Algorithm description}
The initial optimization attempts were carried out using standard algorithms available in the \texttt{SciPy} library \cite{SciPy-NMeth}.
In the following sections, I present the specific algorithm used and discuss the results obtained from its application to the problem of gate fidelity optimization.

\subsubsection{Nelder-Mead}
The first gradient-free optimization method to be tested was Nelder-Mead since in letteratura era già stato riportato il suo utilizzo per obiettivi simili \cite{kelly_optimal_2014}.

The Nelder-Mead optimization method, originally introduced by Nelder and Mead in 1965 \cite{NelderMeads}, is a widely used numerical optimization technique for unconstrained problems in multidimensional spaces. \\
This derivative-free method is operates using simplex, which is a polytope of $n+1$ vertices in a $n$-dimensional space.
The algorithm iteratively updates the simplex by replacing its worst-performing vertex with a new candidate point, thereby guiding the search towards an optimal solution. 
If the goal is to minimize a given function $f(\mathbf{x})$ where $\mathbf{x} \in \mathbb{R}^n$ the algorithms proceeds with the following steps:\begin{enumerate}
    \item If not otherwise initialized, $n+1$ points are sampled for building the initial symplex
    \item \tt{Order} the test points according to their values at vertices: $f(\mathbf{x}_1) \leq f(\mathbf{x}_2) \leq \dots \leq f(\mathbf{x}_{n+1})$ and check whether the algorithm should terminate.
    \item \tt{Calculate} $\mathbf{x}_0$, the centroid of all points except $\mathbf{x}_{n+1}$.
    \item \tt{Reflection}: Compute the reflected point $\mathbf{x}_r = \mathbf{x}_0 + \alpha(\mathbf{x}_0 - \mathbf{x}_{n+1})$ with $\alpha > 0$. 
            If $\mathbf{x}_r$ satisfies $f(\mathbf{x}_1) \leq f(\mathbf{x}_r) < f(\mathbf{x}_n)$, then a new simplex is obtained by replacing the worst-performing point $\mathbf{x}_{n+1}$ with $\mathbf{x}_r$ and then go to step 1.
    \item \tt{Expansion}: If $\mathbf{x_r}$ is the current best point, meaning that $f(\mathbf{x}_r) < f(\mathbf{x}_1)$, then the expanded point is computed: $\mathbf{x}_e = \mathbf{x}_0 + \gamma(\mathbf{x}_r-\mathbf{x}_0)$ with $\gamma>1$.
           If $\mathbf{x}_e$ satisfies $f(\mathbf{x}_e) < f(\mathbf{x}_r)$, then a new simplex is obtained by replacing $\mathbf{x}_{n+1}$ with the expanded point $\mathbf{x}_e$ and then go to step 1.\\
            If instead $f(\mathbf{x}_e) \geq f(\mathbf{x}_r)$, the new simplex is obtained by replacing $\mathbf{x}_{n+1}$ with $\mathbf{x}_r$, and then go to step 1.
    \item \tt{Contraction}: In this case is certain that $f(\mathbf{x}_r) \geq f(\mathbf{x}_n)$ then:\begin{itemize}
        \item If $f(\mathbf{x}_r) < f(\mathbf{x}_{n+1})$: compute the contracted point $\mathbf{x}_c=\mathbf{x}_0 +\rho(\mathbf{x}_{r}-\mathbf{x}_0)$ with $0<\rho \leq 0.5$.
                If $\mathbf{x}_c$ satisfies $f(\mathbf{x}_c) < f(\mathbf{x}_{r})$, then a new simplex is obtained by replacing $\mathbf{x}_{n+1}$ with  $\mathbf{x}_c$ and go to step 1.\\
                Else go to step 6.
        \item  If $f(\mathbf{x}_r) \geq f(\mathbf{x}_{n+1})$: compute the contracted point $\mathbf{x}_c=\mathbf{x}_0 +\rho(\mathbf{x}_{n+1}-\mathbf{x}_0)$ with $0<\rho \leq 0.5$.
                If $\mathbf{x}_c$ satisfies $f(\mathbf{x}_c) < f(\mathbf{x}_{n+1})$, the a new simplex is constructed with $\mathbf{x}_c$ and go to step 1.\\
                Else go to step 6.
    \end{itemize}
    \item \tt{Shrinkage}: Replace all points except the best, $\mathbf{x}_1$, with $\mathbf{x}_i = \sigma(\mathbf{x}_i - \mathbf{x}_1), 0<\sigma \leq 0.5$  
\end{enumerate}
The algorithm terminates when the standard deviation of the function values of the current simplex fall below a user-initialized tolerance. 
When the cycle stops the point of the simplex associated to the lower function value is returned as proposed optimum

The values of the parameters $\alpha, \gamma, \rho$ and $\sigma$ were left to default of \tt{scipy}: $\alpha=1, \gamma=2, \rho=0.5, \sigma=0.5$. 

\subsubsection{SLSQP}
Per valutare eventuali miglioramenti nella performance abbiamo provato ad utilizzare un algoritmo che fosse gradient-based. 
Nello specifico ho provato ad utilizzare l'algoritmo di Sequential Least Squares Programming (SLSQP) nella versione implementata all'interno della libreria scipy.
Method SLSQP uses Sequential Least SQuares Programming to minimize a function of several variables with any combination of bounds, equality and inequality constraints. 
The method wraps the SLSQP Optimization subroutine originally implemented by Dieter Kraft \cite{kraft1988slsqp}.  
Note that the wrapper handles infinite values in bounds by converting them into large floating values.

Sequential Least Squares Programming (SLSQP) is a numerical algorithm designed for solving constrained nonlinear optimization problems of the general form:
\begin{align*}
& \min_{x \in \mathbb{R}^n} \quad && f(x) \\
& \text{subject to} \quad && c_i(x) = 0, \quad i = 1, \dots, m \\
& && d_j(x) \geq 0, \quad j = 1, \dots, p
\end{align*}

It belongs to the family of Sequential Quadratic Programming (SQP) methods, which iteratively solve a sequence of quadratic programming subproblems that approximate the original nonlinear problem. 
At each iteration, the nonlinear objective function is replaced by a quadratic model, and the constraints are linearized around the current iterate. 
The resulting subproblem is a quadratic program whose solution provides a direction for updating the optimization variables.

The quadratic model is typically derived from the Lagrangian function associated with the problem,
\begin{equation}
\mathcal{L}(x, \lambda, \mu) = f(x) - \sum_{i} \lambda_i c_i(x) - \sum_{j} \mu_j d_j(x),
\end{equation}
where $ \lambda $ and $ \mu $ are the Lagrange multipliers associated with the equality and inequality constraints, respectively. 
The Hessian of the Lagrangian is not computed explicitly; instead, SLSQP employs a quasi-Newton approximation, updated using a BFGS-like scheme. 
Although it does not implement the BFGS algorithm in the strict sense, the use of such updates places SLSQP within the broader class of quasi-Newton SQP algorithms.

A constrained line search is performed along the computed search direction to ensure sufficient decrease in a merit function that balances objective reduction and constraint satisfaction. 
This ensures both global convergence and rapid local convergence near a solution. 
The process continues until convergence criteria, typically based on the projected gradient norm and constraint residuals, are satisfied.

\subsection{Results}
In the following I present the results obtained provando ad effettuare l'ottimizzaione con l'algoritmo di Nelder-Meads

\begin{tabular}{lcccccc}
    \textbf{Method} & \textbf{Success} & \textbf{Status} & \textbf{Objective Value} & \textbf{Iterations} & \textbf{Duration}\\
    \textbf{Nelder-Mead} & False & 2 & 0.002732 & 40 & 93 & No initial symplex\\
    \textbf{Nelder-Mead}
\end{tabular}

\section{CMA-ES}

\subsection{Algorithm description}
Covariance Matrix Adaptation Evolution Strategy (\tt{CMA-ES} \cite{cmaessimplepractical}), is a population-based evolutionary algorithm designed for optimizing complex, non-convex, and high-dimensional functions.\\
It belongs to the broader class of Evolution Strategies (ES), a subset of Evolutionary Algorithms (EAs)(see \cite{sloss20192019evolutionaryalgorithmsreview}), and is particularly effective for black-box optimization where gradient information is unavailable.

Evolution Strategies (ES) are a class of optimization methods that employ self-adaptive mechanisms to explore the search space efficiently. 
Unlike classical optimization techniques that rely on gradient descent, ES leverage stochastic sampling to navigate rugged and multimodal landscapes.
In this context, CMA-ES is an adaptive stochastic search method that iteratively refines a probability distribution over the search space. 
Unlike traditional Genetic Algorithms (GAs), which rely on crossover and mutation operators, CMA-ES employs a multivariate normal distribution to generate candidate solutions. 
The method adaptively updates the distribution's mean and covariance matrix based on the fitness of sampled points.

The fundamental idea behind CMA-ES is the use of a multivariate Gaussian distribution to model promising search directions. 
Let $\mathbf{\mu}_t$ denote the mean of the distribution at iteration $t$, and $\Sigma_t$ the covariance matrix. 
Then, a new population of $\lambda$ candidate solutions $\mathbf{x}_i^(t+1) \sim \mathbf{\mu}_t + \sigma_t\mathcal{N}(0, \Sigma_t)$, where $\sigma_t$ is a step size controlling the exploration.  

The CMA-ES algorithm follows the following steps:\begin{enumerate}
    \item If not otherwise specified, the initial parameters are set: mean vector $\mathbf{\mu_0}$, covariance matrix $\Sigma_0$\footnote{$\Sigma_0=\mathbb{I}$ for isotropic search}, step size $\sigma_0$, population size $\lambda$
    \item Generate $\lambda$ new candidate solutions $\mathbf{x}_i$ according to a multivariate normal distribution.
    \item Evaluate the objective function $f(\mathbf{x}_i)$ for each candidate solution.
    \item Sort the new candidate solutions based on fitness: $f(\mathbf{x}_0) \leq ... \leq f(\mathbf{x}_{\lambda})$.
    \item Update the mean vector $\mathbf{\mu}$ with the $m=\lfloor \lambda / 2 \rfloor$ top performing solutions:\begin{equation}
        \mathbf{\mu} \leftarrow \sum_{i=0}^m \mathbf{w}_i\mathbf{x}_1,
    \end{equation} where $\mathbf{w}_i$ are internally defined weights.
    \item Update the isotropic and anisotropic evolution path $\mathbf{p}_{\sigma}$, $\mathbf{p}_c$ \footnote{For details on the update process of the evolution paths see \cite{cmaessimplepractical}.}.
    \item Update the covariance matrix: \begin{equation}
        C \leftarrow (1 - c_1 - c_{\mu}) C + c_1 \mathbf{p}_c \mathbf{p}_c^T + c_{\mu} \sum_{i=1}^{\mu} w_i \mathbf{y}_i \mathbf{y}_i^T,
    \end{equation} where $c_1$ and $c_\mu$ are learning rates and $\mathbf{y}_i$ represents the deviation of the $i$-th cnadidate solution from the mean $\mathbf{mu}$.
    \item Update the step size using a cumulative path evolution mechanism \begin{equation}
        \sigma \leftarrow \sigma \cdot \exp \left( \frac{c_{\sigma}}{d_{\sigma}} \left( \| \mathbf{p}_{\sigma} \| - E \| \mathcal{N}(0, I) \| \right) \right),
    \end{equation} where $c_\sigma$ is the learning rate for step-size adaptation, $d_\sigma$ is a damping factor $\| \mathbf{p}_{\sigma} \|$ is the length of the evolution path and $E \| \mathcal{N}(0, I) \|$ is the expected length of a standard normally distributed random vector.
\end{enumerate}

Nel seguito, a meno che non sia diversamente specificato, i parametri sono stati inizializzati ai valori di default della libereria \tt{CMA-ES}
\subsection{Results}


\section{Optuna}

\subsection{Algorithm description}

In addition to the optimization methods mentioned earlier, the Tree-Structured Parzen Estimator (TPE) method was employed, using its implementation available in the \texttt{optuna} library \cite{optuna_2019}.

Tree-Structured Parzen Estimator (TPE) is a Sequential Model-Based Optimization (SMBO) approach \cite{SMBO_proceedings}. 
SMBO methods sequentially construct models to approximate the performance of optimization parameters based on historical measurements, and then subsequently choose new parameters values to test based on this model. \cite{BayesianOptimizationReview}
At the heart of SMBO is the idea of building a surrogate model, which is used to predict the objective function's values for unseen parameters configurations. 
The surrogate model is iteratively updated as new observations are made, and the optimization process balances exploration, which focuses on uncertain regions of the search space, and exploitation, which focuses on areas that are more likely to improve the objective based on past evaluations. 
This balance ensures that the optimization process makes efficient use of resources and avoids wasting time on suboptimal regions.\\

The TPE algorithm is a probabilistic model-based optimization method that uses non-parametric density estimation to guide the search. 
The TPE algorithm differs from traditional Bayesian optimization approaches, such as Gaussian Process-based methods, in its modeling strategy. 
Rather than directly approximating the objective function, TPE constructs two separate probabilistic models:

\begin{itemize}
    \item $p(x | y < y^*)$, the likelihood of observing a parameter configuration $x$ given that the objective function value $y$ is below a chosen threshold $y^*$.
    \item $p(x | y \geq y^*)$, the likelihood of observing $X$ for less promising function values.
\end{itemize}

These probability densities are estimated using non-parametric methods such as kernel density estimation (KDE). 
New candidate points are then generated by sampling from $p(x | y < y^*)$, favoring configurations that are expected to yield lower objective values. The threshold $y^*$ is typically set as a quantile of observed values, ensuring a focus on the most promising regions of the search space.

The TPE method is the default optimization strategy in \tt{Optuna}, an advantage in the optimization algorithm as implemented in optuna is the addition of an authomatic \textit{pruning} mechanism that stops  unpromising trials early, which can significantly speed up the optimization process by avoiding unnecessary computations.
In our case, this is particularly relevant because the execution of the RB routine, which is performed at each call to the cost function, requires [insert approximate execution time]

As implemented in our code, the default pruner used is the median pruner \tt{optuna.pruners.MedianPruner}. 
This pruner works by evaluating the intermediate results of a trial and comparing them to the median of completed trials at the same step. 
If the current trial's performance is worse than the median, it is pruned to prevent wasting computational resources on unpromising configurations. 

\subsection{Results}

\subsection{$\beta$ parameter impact on RB optimization}

\paragraph{D1 - steps}

\paragraph{D1 - 1000 steps}

\paragraph{D2 - 1000 steps}



\section{RB optimization conclusions}

\begin{tabular}{lccccc}
    \textbf{Method} & \textbf{Highest Fidelity} & \textbf{Amplitude [a.u.]} & \textbf{Frequency [GHz]} & \textbf{$\beta$} \\

\end{tabular}