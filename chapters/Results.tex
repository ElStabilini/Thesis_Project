Tutti i risultati che sono presentati nel seguito sono stati ottenuti utilizzando il software di \Qibolab per l'interazione con gli strumenti del laboratorio e \Qibocal per il controllo delle operazioni sui qubit.
L'hardware è un chip di QunatumWare. %chiedere dettagli sul chip
Durante il lavoro condotto per questo progetto di tesi entrambe le libererie, sia Qibocal che Qibolab undergo update and release, for this reason the first part of this work was realized using \Qibocal v0.1 and \Qibolab v0.1 while the second part of the work, 
dato che puntava anche allo sviluppo di routine ch epotessero essere utili per la calibrazione dei qubit è stato realizzato direttamente con \Qibocal v0.2 e \Qibolab v0.2. 

\section{RB fidelity optimization}

\subsection{Randomized Benchmarking}\label{RBsection}
A strong limitation to the realization of quantum computing technologies is the loss of coherence that happens as a consequence of the application of many sequential quantum gates to to the quibts.
A possible approach to characterize gate error is the quantum process tomography which allows the experimenter to establish the behaviour of a quantum gates; the main drawback of this approach is that process tomography can be very time consumig since its time complexity scales exponentially with the number of qubits involved \cite{QPTomography} and the result is affected by state preparation and measurements (SPAM) errors.

To overcome these limitations, randomized benchmarking (RB) was introduced and is currently widely used to quantify the avarage error rate for a set of quantum gates.

The main idea is that the error obtained from the combined action of random unitary gates drawn from a uniform distribution with respect to the Haar measure \cite{Mele_2024} and applied in sequence to the qubit will avarage out to behave like a depolarizing channel \cite{Emerson_2005_RB}.
This last consideration simplifies the characterization of noise because it removes dependence on specific error structures and allows fidelity to be extracted through a simple exponential decay.

It was later shown that it is possible to simplify this procedure even more, by restricting the unitaries to gates in the Clifford group \footnote{unitary rotations mapping the group of Puali operators in itself} and by not requiring that the sequence is strictly self-inverting \cite{knill_randomized_2008}.
\begin{comment}
    The Haar measure is crucial because it provides a unique, invariant way of selecting random elements from a group (in this case, unitary gates) that ensures the randomness is truly uniform and unbiased across the group's structure.
\end{comment}

The fundamental principle of RB is the application of sequences of randomly selected quantum gates from the Clifford group $\mathcal{C}$ followed by an inversion gate which, in absence of noise, return the system to its initial state. 
For real systems, where noise is present, the observed survival probability provides an estimate of the avarage gate fidelity.


The standard RB protocols consist of the following steps:\begin{enumerate}\label{routine:RB}
    \item Initialize the system in ground state $\ket{0}$
    \item For each sequence-length $m$ build a sequence of $m$ randomly drawn Clifford gates $C_1, C_2, ..., C_m$
    \item Determine the inverse gate $C_{m+1}=(C_m\circ...\circ C_1)^{-1}$
    \item Measure $C_{m+1}\circ C_m \circ ...\circ C_1 \ket{0}$
\end{enumerate}
The process must be repeated for multiple sequence of the same length and with varying length.

In ideal systems without noise we should have 
\begin{equation}\label{eq:CliffordIdeal}
    C_{m+1}\circ C_m \circ ...\circ C_1 \ket{0} = (C_m\circ...\circ C_1)^{-1}\circ(C_m\circ...\circ C_1)\ket{0} = \ket{0}
\end{equation}

In realsystems, where noise is present, eq. \ref{eq:CliddordIdeal} does not hold; instead randomization with Clifford gates behave as a depolarizing channel \ref{eq:depolarizing_channel} with depolarization probability $d$.
The survival probability of the initial state $\ket{0}$ for different sequence lengths follows the exponential decay model \begin{equation}
    F(m) = Ap^m +B,
\end{equation}
where $1-p$ is the rate of depolarization and $A$ and $B$ capture the state preparation and measurement error but not the rate of decay $p$. 
Note that the exponential form arises naturally due to the assumption that each gate introduces independent noise.

\begin{comment}
    The exponential form arises from modeling each gate application as an independent error process. When you compose multiple noisy gates, their error contributions multiply, leading naturally to an exponential decay.
\end{comment}    

The parameter $p$ is directly related to the depolarization probability $d$ through the avarage gate fidelity $F$ which, for a depolarizing channel, is given by \begin{equation}
    F = 1 - \frac{d}{2^n - 1}\label{eq:avarage_gate_fidelity}.
\end{equation}
For the details of the calculations to obtain eq. \ref{eq:avarage_gate_fidelity} see Appendix A (\ref{Appendix:A}).

Now we can derive the avarage error per Clifford gate $\epsilon_{Clifford}$ \begin{equation}
    \epsilon_{Clifford} = 1 - F \label{eq:avg_error_Clifford_gate},
\end{equation}
where $F$ is the avarage gate fidelity. Sobstituting in \ref{eq:avg_error_Clifford_gate} the formula for the avarage gate fidelity \ref{eq:avarage_gate_fidelity} we obtain \begin{equation}
    \epsilon_{Clifford} = \frac{d}{2^n -1} = \frac{1-p}{1-2^{-n}},
\end{equation}
which shows how the avarage error per Clifford gate is directly connected to the exponential decay rate.

\subsubsection{QUA Randomized Benchmarking}
For the results we present in the following the technique used slightly differs from the one described in section \ref{RBsection} 
%dato che il tempo richiesto per eseguire una standard RB è dell'ordine di .. la routine su cui sono stari relizzati gli esperimenti è una variante più rapida che è stata implementata sulla base di quanto rirportato in

\subsection{Optimization methods}\label{Sec:OptimizationMethods}
I primi metodi che abbiamo provato per l'ottimizzazione dei parametri sono quelli standard implementati nella libreria \tt{Scipy} \cite{SciPy-NMeth} evitando metodi gradient-based considerato il landscape potenzialmente complicato della funzione RB.
The first gradient-free optimization method to be tested was Nelder-Mead since in letteratura era già stato riportato il suo utilizzo per obiettivi simili \cite{kelly_optimal_2014}.

The Nelder-Mead optimization method, originally introduced by Nelder and Mead in 1965 \cite{NelderMeads}, is a widely used numerical optimization technique for unconstrained problems in multidimensional spaces. \\
This derivative-free method is operates using simplex, which is a polytope of $n+1$ vertices in a $n$-dimensional space.
The algorithm iteratively updates the simplex by replacing its worst-performing vertex with a new candidate point, thereby guiding the search towards an optimal solution. 
If the goal is to minimize a given function $f(\mathbf{x})$ where $\mathbf{x} \in \mathbb{R}^n$ the algorithms proceeds with the following steps:\begin{enumerate}
    \item If not otherwise initialized, $n+1$ points are sampled for building the initial symplex
    \item \tt{Order} the test points according to their values at vertices: $f(\mathbf{x}_1) \leq f(\mathbf{x}_2) \leq \dots \leq f(\mathbf{x}_{n+1})$ and check whether the algorithm should terminate.
    \item \tt{Calculate} $\mathbf{x}_0$, the centroid of all points except $\mathbf{x}_{n+1}$.
    \item \tt{Reflection}: Compute the reflected point $\mathbf{x}_r = \mathbf{x}_0 + \alpha(\mathbf{x}_0 - \mathbf{x}_{n+1})$ with $\alpha > 0$. 
            If $\mathbf{x}_r$ satisfies $f(\mathbf{x}_1) \leq f(\mathbf{x}_r) < f(\mathbf{x}_n)$, then a new simplex is obtained by replacing the worst-performing point $\mathbf{x}_{n+1}$ with $\mathbf{x}_r$ and then go to step 1.
    \item \tt{Expansion}: If $\mathbf{x_r}$ is the current best point, meaning that $f(\mathbf{x}_r) < f(\mathbf{x}_1)$, then the expanded point is computed: $\mathbf{x}_e = \mathbf{x}_0 + \gamma(\mathbf{x}_r-\mathbf{x}_0)$ with $\gamma>1$.
           If $\mathbf{x}_e$ satisfies $f(\mathbf{x}_e) < f(\mathbf{x}_r)$, then a new simplex is obtained by replacing $\mathbf{x}_{n+1}$ with the expanded point $\mathbf{x}_e$ and then go to step 1.\\
            If instead $f(\mathbf{x}_e) \geq f(\mathbf{x}_r)$, the new simplex is obtained by replacing $\mathbf{x}_{n+1}$ with $\mathbf{x}_r$, and then go to step 1.
    \item \tt{Contraction}: In this case is certain that $f(\mathbf{x}_r) \geq f(\mathbf{x}_n)$ then:\begin{itemize}
        \item If $f(\mathbf{x}_r) < f(\mathbf{x}_{n+1})$: compute the contracted point $\mathbf{x}_c=\mathbf{x}_0 +\rho(\mathbf{x}_{r}-\mathbf{x}_0)$ with $0<\rho \leq 0.5$.
                If $\mathbf{x}_c$ satisfies $f(\mathbf{x}_c) < f(\mathbf{x}_{r})$, then a new simplex is obtained by replacing $\mathbf{x}_{n+1}$ with  $\mathbf{x}_c$ and go to step 1.\\
                Else go to step 6.
        \item  If $f(\mathbf{x}_r) \geq f(\mathbf{x}_{n+1})$: compute the contracted point $\mathbf{x}_c=\mathbf{x}_0 +\rho(\mathbf{x}_{n+1}-\mathbf{x}_0)$ with $0<\rho \leq 0.5$.
                If $\mathbf{x}_c$ satisfies $f(\mathbf{x}_c) < f(\mathbf{x}_{n+1})$, the a new simplex is constructed with $\mathbf{x}_c$ and go to step 1.\\
                Else go to step 6.
    \end{itemize}
    \item \tt{Shrinkage}: Replace all points except the best, $\mathbf{x}_1$, with $\mathbf{x}_i = \sigma(\mathbf{x}_i - \mathbf{x}_1), 0<\sigma \leq 0.5$  
\end{enumerate}
The algorithm terminates when the standard deviation of the function values of the current simplex fall below a user-initialized tolerance. 
When the cycle stops the point of the simplex associated to the lower function value is returned as proposed optimum

The values of the parameters $\alpha, \gamma, \rho$ and $\sigma$ were left to default of \tt{scipy}: $\alpha=1, \gamma=2, \rho=0.5, \sigma=0.5$. 

\paragraph{\tt{CMA-ES}}
Covariance Matrix Adaptation Evolution Strategy (\tt{CMA-ES}) is a population-based evolutionary algorithm designed for optimizing complex, non-convex, and high-dimensional functions.\\
It belongs to the broader class of Evolution Strategies (ES), a subset of Evolutionary Algorithms (EAs)(see \cite{sloss}), and is particularly effective for black-box optimization where gradient information is unavailable or unreliable. 
\cite{cmaessimplepractical}

\paragraph{\tt{Optuna}}
\cite{optuna_2019}


\section{RX90 calibration}
Another possible source of error is ...

\section{Flux pulse correction}
\subsection{Notes on signal analysis}


\subsection{Cryoscope}
The experiment that we describe in this section was first introduced in \cite{rol_time-domain_2020}, the goal is to determine predistortions that needs to be applied to a flux pulse signal so that the qubit receives the flux pulse as intended by the experimenter.

\begin{comment}
    TO DO LIST:
    * calcoli analitici per assunzioni del cryoscope
    * calcoli analitici di convoluzioni per dimostrare che è giusto il modo in cui combiniamo i filtri
    * costruire script per analisi dati
    * eventualmente provare ad aggiungere più correzioni esponenziali
\end{comment}
\subsection{Filter determination}
\subsubsection{IIR}
\subsubsection{FIR}
for description and notes on \tt{CMA-ES} see section \ref{Sec:OptimizationMethods}
\subsubsection{Output filters in QM}
